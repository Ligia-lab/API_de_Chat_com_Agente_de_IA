# Provider do modelo de linguagem (LLM)
LLM_PROVIDER=ollama

# Nome do modelo no Ollama
LLM_MODEL=llama3

# Parâmetros do modelo
LLM_TEMPERATURE=0.2

# Máximo de tokens na resposta
LLM_MAX_TOKENS=1024

# Ambiente da aplicação
APP_ENV=local
